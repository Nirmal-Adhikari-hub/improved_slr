seed: 42

dataset_info:
  evaluation_dir: "./cslr/models/slowfast/evaluation/slr_eval"
  evaluation_prefix: "phoenix2014-groundtruth" 

data:
  dataset: "phoenix2014"
  dataset_root: "/nas/Dataset/Phoenix/phoenix2014-release/phoenix-2014-multisigner"
  # dataset_root: "/shared/home/xvoice/nirmal/SlowFastSign/dataset/phoenix2014/phoenix-2014-multisigner"
  frame_subdir: "features/fullFrame-256x256px"
  preprocess_root: "./preprocess"
  gloss_dict_path: "./preprocess/phoenix2014/gloss_dict.npy"

  datatype: "video"
  frame_interval: 1
  image_scale: 1.0
  input_size: 224

  # Fallback; we will replace with model.kernel_spec after model init
  kernel_spec: ["K5","P2","K5","P2"]

  batch_size: 4
  num_workers: 4

model:
  name: "legacy_slowfast"
  num_classes: 1296
  blank_id: 0

  # Adapter-specific args:
  c2d_type: "slowfast101"                   # authors’ R101 backbone
  slowfast_config: "SLOWFAST_64x2_R101_50_50.yaml"
  slowfast_args: []                         # you can pass cfg overrides here if needed
  conv_type: 2
  use_bn: 1
  hidden_size: 1024
  load_pkl: false # [IMPORTANT -  make this true in real training]
  weight_norm: true
  share_classifier: 1

  # used if inner.conv1d.kernel_size is unavailable
  kernel_spec: ["K5","P2","K5","P2"]

  # authors’ loss selections/weights
  loss_weights:
    SeqCTC: 1.0
    # VAC
    ConvCTC: 1.0
    Dist: 25.0
  #load_weights: ''

optimiser:
  name: "adamw"
  lr: 1.0e-4
  weight_decay: 1.0e-2

scheduler:
  name: "cosine"
  t_max: 50
  eta_min: 1.0e-6

trainer:
  epochs: 1
  save_dir: "outputs"
  grad_accum_steps: 1
  amp: true
  ema: false
  ema_decay: 0.999

  resume: true
  ema: true
  ema_decay: 0.999
  save_best_by: "dev_wer" # "dev_wer_ema" | "dev_wer" (primary metric)
  log_interval: 50

logging:
  tensorboard: true
  use_wandb: true
  sync_tb: true
  wandb_project: "cslr-slowfast"
  wandb_tags: ["phoenix2014", "slowfast", "step1"]
  wandb_watch_gradients: false # gradients can be heavy
  wandb_watch_freq: 200
  wandb_log_artifacts: true # upload last.pth each epoch
  # control when to upload model artifact to W&B
  wandb_artifact_policy: "end" # one of "none" | "every_epoch" | "end"

eval:
  decode: "beam" # "beam" | "greedy" ("greedy" not supported yet)
  beam_width: 10 # as in the original slowfast repo
  run_test_mid_epoch: true # mid-epoch test eval
  log_examples: 0 # how many (ref vs hyp) pairs to print; 0 disables


#### Feeder Indices [0,1,2,62,414] -> Test
#### Feeder Indices [0,68,5670,2275] -> Train
#### Feeder Indices [0,21,539,107] -> Dev
sanity_checks:
  enabled: true
  set: "train" # dataset to pass through model's forward pass. "train" | "dev" 
  index: 2275 # index of the sample
  # author_ckpt_path: "/shared/home/xvoice/nirmal/gradcam/checkpoints/slow_fast_phoenix2014_dev_18.01_test_18.28.pt"
  author_ckpt_path: "/home/nirmal/SlowFast/GradCAMs/checkpoints/slow_fast_phoenix2014_dev_18.01_test_18.28.pt"


